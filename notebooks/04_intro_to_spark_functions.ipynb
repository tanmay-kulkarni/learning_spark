{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bdd9579-4e99-4a7d-8143-a5ed48aeba1a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99f6d5b9-b1f9-4d8d-b0e6-c16b32bc60eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---+------+-------------+-----------------+----------+------------+-------------------+---------------+\n|user_id| name|age|gender|         city|       occupation| education|weight_in_kg|      time_of_birth|date_of_joining|\n+-------+-----+---+------+-------------+-----------------+----------+------------+-------------------+---------------+\n|      1| John| 25|  Male|     New York|         Engineer|Bachelor's|        70.5|1995-05-10 08:30:00|     2020-01-01|\n|      2| Jane| 30|Female|San Francisco|           Doctor|  Master's|        65.2|1990-08-15 12:00:00|     2018-06-15|\n|      3| Mike| 35|  Male|      Chicago|          Teacher|       PhD|        80.7|1985-03-20 10:45:00|     2015-03-01|\n|      4|Emily| 28|Female|  Los Angeles|           Lawyer|Bachelor's|        60.9|1992-11-05 09:15:00|     2019-09-10|\n|      5|David| 32|  Male|      Seattle|Software Engineer|  Master's|        75.3|1988-07-25 14:30:00|     2017-04-05|\n+-------+-----+---+------+-------------+-----------------+----------+------------+-------------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pyspark.sql import Row\n",
    "\n",
    "attributes = [\"user_id\", \"name\", \"age\", \"gender\", \"city\", \"occupation\", \"education\", \"weight_in_kg\", \"time_of_birth\", \"date_of_joining\"]\n",
    "\n",
    "users = [\n",
    "    {\n",
    "        \"user_id\": 1,\n",
    "        \"name\": \"John\",\n",
    "        \"age\": 25,\n",
    "        \"gender\": \"Male\",\n",
    "        \"city\": \"New York\",\n",
    "        \"occupation\": \"Engineer\",\n",
    "        \"education\": \"Bachelor's\",\n",
    "        \"weight_in_kg\": 70.5,\n",
    "        \"time_of_birth\": datetime.datetime(1995, 5, 10, 8, 30),\n",
    "        \"date_of_joining\": datetime.date(2020, 1, 1)\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 2,\n",
    "        \"name\": \"Jane\",\n",
    "        \"age\": 30,\n",
    "        \"gender\": \"Female\",\n",
    "        \"city\": \"San Francisco\",\n",
    "        \"occupation\": \"Doctor\",\n",
    "        \"education\": \"Master's\",\n",
    "        \"weight_in_kg\": 65.2,\n",
    "        \"time_of_birth\": datetime.datetime(1990, 8, 15, 12, 0),\n",
    "        \"date_of_joining\": datetime.date(2018, 6, 15)\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 3,\n",
    "        \"name\": \"Mike\",\n",
    "        \"age\": 35,\n",
    "        \"gender\": \"Male\",\n",
    "        \"city\": \"Chicago\",\n",
    "        \"occupation\": \"Teacher\",\n",
    "        \"education\": \"PhD\",\n",
    "        \"weight_in_kg\": 80.7,\n",
    "        \"time_of_birth\": datetime.datetime(1985, 3, 20, 10, 45),\n",
    "        \"date_of_joining\": datetime.date(2015, 3, 1)\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 4,\n",
    "        \"name\": \"Emily\",\n",
    "        \"age\": 28,\n",
    "        \"gender\": \"Female\",\n",
    "        \"city\": \"Los Angeles\",\n",
    "        \"occupation\": \"Lawyer\",\n",
    "        \"education\": \"Bachelor's\",\n",
    "        \"weight_in_kg\": 60.9,\n",
    "        \"time_of_birth\": datetime.datetime(1992, 11, 5, 9, 15),\n",
    "        \"date_of_joining\": datetime.date(2019, 9, 10)\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 5,\n",
    "        \"name\": \"David\",\n",
    "        \"age\": 32,\n",
    "        \"gender\": \"Male\",\n",
    "        \"city\": \"Seattle\",\n",
    "        \"occupation\": \"Software Engineer\",\n",
    "        \"education\": \"Master's\",\n",
    "        \"weight_in_kg\": 75.3,\n",
    "        \"time_of_birth\": datetime.datetime(1988, 7, 25, 14, 30),\n",
    "        \"date_of_joining\": datetime.date(2017, 4, 5)\n",
    "    }\n",
    "]\n",
    "\n",
    "users_as_spark_rows = [Row(**user) for user in users]\n",
    "\n",
    "df = spark.createDataFrame(users_as_spark_rows)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ceb98bb-65aa-4d5e-b1c8-185432875ce4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caf0348e-608b-468f-b55e-e541a43f80c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- user_id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- age: long (nullable = true)\n |-- gender: string (nullable = true)\n |-- city: string (nullable = true)\n |-- occupation: string (nullable = true)\n |-- education: string (nullable = true)\n |-- weight_in_kg: double (nullable = true)\n |-- time_of_birth: timestamp (nullable = true)\n |-- date_of_joining: date (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a9c0ba2-308b-419b-9122-589761cf6790",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Show datatype of each column in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eeb0378-53d7-4eec-b567-907bc9da96ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('user_id', 'bigint'),\n",
       " ('name', 'string'),\n",
       " ('age', 'bigint'),\n",
       " ('gender', 'string'),\n",
       " ('city', 'string'),\n",
       " ('occupation', 'string'),\n",
       " ('education', 'string'),\n",
       " ('weight_in_kg', 'double'),\n",
       " ('time_of_birth', 'timestamp'),\n",
       " ('date_of_joining', 'date')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43990050-2562-4a35-a99e-76d217010e12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method withColumn in module pyspark.sql.dataframe:\n\nwithColumn(colName: str, col: pyspark.sql.column.Column) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n    Returns a new :class:`DataFrame` by adding a column or replacing the\n    existing column that has the same name.\n    \n    The column expression must be an expression over this :class:`DataFrame`; attempting to add\n    a column from some other :class:`DataFrame` will raise an error.\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    colName : str\n        string, name of the new column.\n    col : :class:`Column`\n        a :class:`Column` expression for the new column.\n    \n    Returns\n    -------\n    :class:`DataFrame`\n        DataFrame with new or replaced column.\n    \n    Notes\n    -----\n    This method introduces a projection internally. Therefore, calling it multiple\n    times, for instance, via loops in order to add multiple columns can generate big\n    plans which can cause performance issues and even `StackOverflowException`.\n    To avoid this, use :func:`select` with multiple columns at once.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n    >>> df.withColumn('age2', df.age + 2).show()\n    +---+-----+----+\n    |age| name|age2|\n    +---+-----+----+\n    |  2|Alice|   4|\n    |  5|  Bob|   7|\n    +---+-----+----+\n\n"
     ]
    }
   ],
   "source": [
    "help(df.withColumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c73d4481-d3ef-48f9-8402-08f4f6ea5957",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "799bd850-496d-48ac-b1e0-475f1bd46bd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function col in module pyspark.sql.functions.builtin:\n\ncol(col: str) -> pyspark.sql.column.Column\n    Returns a :class:`~pyspark.sql.Column` based on the given column name.\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Supports Spark Connect.\n    \n    Parameters\n    ----------\n    col : str\n        the name for the column\n    \n    Returns\n    -------\n    :class:`~pyspark.sql.Column`\n        the corresponding column instance.\n    \n    Examples\n    --------\n    >>> col('x')\n    Column<'x'>\n    >>> column('x')\n    Column<'x'>\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "help(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34d7dc0c-1f35-4f8d-8153-161047a789de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---+------------+------+\n|user_id| name|age|weight_in_kg|weight|\n+-------+-----+---+------------+------+\n|      1| John| 25|        70.5|  70.5|\n|      2| Jane| 30|        65.2|  65.2|\n|      3| Mike| 35|        80.7|  80.7|\n|      4|Emily| 28|        60.9|  60.9|\n|      5|David| 32|        75.3|  75.3|\n+-------+-----+---+------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select('user_id', 'name', 'age', 'weight_in_kg').withColumn('weight', col('weight_in_kg')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a78cf69c-be8f-4cce-b7aa-83ca380e2187",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### withColumnRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be249c7-de16-4f7c-8c5f-4c2514e6076a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+\n|user_id|user_name|user_age|\n+-------+---------+--------+\n|      1|     John|      25|\n|      2|     Jane|      30|\n|      3|     Mike|      35|\n|      4|    Emily|      28|\n|      5|    David|      32|\n+-------+---------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select('user_id', 'name', 'age').withColumnRenamed('name', 'user_name').withColumnRenamed('age', 'user_age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87b683db-c787-4673-a2e6-877e6449b0cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### withColumnsRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cb466f3-5b7c-49d9-a715-8023852c2534",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+\n|user_id|user_name|user_age|\n+-------+---------+--------+\n|      1|     John|      25|\n|      2|     Jane|      30|\n|      3|     Mike|      35|\n|      4|    Emily|      28|\n|      5|    David|      32|\n+-------+---------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select('user_id', 'name', 'age').withColumnsRenamed({'name': 'user_name', 'age': 'user_age'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bfd97e9-df6c-48fc-b380-cbccba6f7f58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### lit and concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e84edb36-171e-4ce2-93cf-ff8c8d193656",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---+------+-------------+-----------------+----------+------------+-------------------+---------------+-------------+\n|user_id| name|age|gender|         city|       occupation| education|weight_in_kg|      time_of_birth|date_of_joining|literal_value|\n+-------+-----+---+------+-------------+-----------------+----------+------------+-------------------+---------------+-------------+\n|      1| John| 25|  Male|     New York|         Engineer|Bachelor's|        70.5|1995-05-10 08:30:00|     2020-01-01|            7|\n|      2| Jane| 30|Female|San Francisco|           Doctor|  Master's|        65.2|1990-08-15 12:00:00|     2018-06-15|            7|\n|      3| Mike| 35|  Male|      Chicago|          Teacher|       PhD|        80.7|1985-03-20 10:45:00|     2015-03-01|            7|\n|      4|Emily| 28|Female|  Los Angeles|           Lawyer|Bachelor's|        60.9|1992-11-05 09:15:00|     2019-09-10|            7|\n|      5|David| 32|  Male|      Seattle|Software Engineer|  Master's|        75.3|1988-07-25 14:30:00|     2017-04-05|            7|\n+-------+-----+---+------+-------------+-----------------+----------+------------+-------------------+---------------+-------------+\n\n+-------+-----+---+------+-------------+-----------------+----------+------------+-------------------+---------------+--------------------+\n|user_id| name|age|gender|         city|       occupation| education|weight_in_kg|      time_of_birth|date_of_joining| name_and_occupation|\n+-------+-----+---+------+-------------+-----------------+----------+------------+-------------------+---------------+--------------------+\n|      1| John| 25|  Male|     New York|         Engineer|Bachelor's|        70.5|1995-05-10 08:30:00|     2020-01-01|      John, Engineer|\n|      2| Jane| 30|Female|San Francisco|           Doctor|  Master's|        65.2|1990-08-15 12:00:00|     2018-06-15|        Jane, Doctor|\n|      3| Mike| 35|  Male|      Chicago|          Teacher|       PhD|        80.7|1985-03-20 10:45:00|     2015-03-01|       Mike, Teacher|\n|      4|Emily| 28|Female|  Los Angeles|           Lawyer|Bachelor's|        60.9|1992-11-05 09:15:00|     2019-09-10|       Emily, Lawyer|\n|      5|David| 32|  Male|      Seattle|Software Engineer|  Master's|        75.3|1988-07-25 14:30:00|     2017-04-05|David, Software E...|\n+-------+-----+---+------+-------------+-----------------+----------+------------+-------------------+---------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, col, concat\n",
    "\n",
    "df.withColumn('literal_value', lit(7)).show()\n",
    "\n",
    "df.withColumn('name_and_occupation', concat('name', lit(', '), 'occupation')).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_intro_to_spark_functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
